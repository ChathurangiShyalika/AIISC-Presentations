# AIISC-Presentations

Paper summaries presented in weekly research meetings of AI Institute, University of South Carolina. 
Lab link : https://aiisc.ai/


1. SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing [Date - March 8, 2022]

Paper link : https://arxiv.org/abs/2110.07205

-Authored by: Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei



2. Knowledge Neurons in Pretrained Transformers [Date - May 30, 2022]

-Authored by: by Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, Furu Wei

Paper link : 
https://arxiv.org/abs/2104.08696 



3. Transformers in Time Series: A Survey [Date - November 07, 2022]

https://www.youtube.com/watch?v=n9WaLsyVjUQ

Transformer is arguably the most successful architecture that offers rapid acceleration conquering vast majority of cutting-edge models in the AI/ML field. A notable instance includes BERT, which, when applied to Google Search, resulted in "one of the biggest leaps forward in the history of Search". Transformers have already dominated Natural Language Processing and Computer Vision, demonstrating excellent performance, and this victory has sparked the rise of transformers in the time series community. How does Transformer models time series? Will it cover underlined challenges in time series? What would be its future?

-Authored by: by Qingsong Wen, Tian Zhou, Chaoli Zhang, Weiqi Chen, Ziqing Ma, Junchi Yan, Liang Sun

Paper link : https://arxiv.org/abs/2202.07125

Presentation link: https://docs.google.com/presentation/d/1VcGSiK1wOEjdGJG2wXSgkjDVzbYes7Q4I2z1otZY8us/edit?usp=sharing


